{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a7caa-bbe1-4b25-8fef-9a459edc3f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ebe2b-c3d1-48cd-ac26-3da715aa63b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs= 250                  #sampling frequency采样频率\n",
    "channel= 22              #number of electrode\n",
    "num_input= 1             #输入通道数（eeg只有一个）\n",
    "num_class= 5             #number of classes 模型需要分类的目标分类数\n",
    "signal_length = 1000      #number of sample in each tarial每个样本包含的数据点\n",
    "\n",
    "F1= 8                    #number of temporal filters时间滤波器的数量\n",
    "D= 3                     #depth multiplier (number of spatial filters)深度乘数（空间滤波器数量）\n",
    "F2= D*F1                 #number of pointwise filters点乘滤波器的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee44dd4-2af7-440f-9945-d46032e5df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size_1= (1,round(fs/2))  #时间维度 跨度为0.5s\n",
    "kernel_size_2= (channel, 1) #空间维度 每次计算所有通道\n",
    "kernel_size_3= (1, round(fs/8)) #时间维度 跨度为0.125s\n",
    "kernel_size_4= (1, 1)\n",
    "\n",
    "kernel_avgpool_1= (1,4) #平均池化层的池化核大小\n",
    "kernel_avgpool_2= (1,8)\n",
    "dropout_rate= 0.2 #防止过拟合\n",
    "\n",
    "#卷积核填充（padding）,保证输入和输出尺寸匹配\n",
    "ks0= int(round((kernel_size_1[0]-1)/2))\n",
    "ks1= int(round((kernel_size_1[1]-1)/2))\n",
    "kernel_padding_1= (ks0, ks1-1)\n",
    "ks0= int(round((kernel_size_3[0]-1)/2))\n",
    "ks1= int(round((kernel_size_3[1]-1)/2))\n",
    "kernel_padding_3= (ks0, ks1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446596d-7350-4f70-b166-741b93782610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Squeeze-and-Excitation (SE) Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y)\n",
    "        return x * y\n",
    "\n",
    "# EEGNet Model with SE and Bidirectional LSTM\n",
    "class EEGNetWithSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEGNetWithSE, self).__init__()\n",
    "\n",
    "        # Layer 1: Initial convolution and batch normalization\n",
    "        self.conv2d = nn.Conv2d(num_input, F1, kernel_size_1, padding=kernel_padding_1)\n",
    "        self.Batch_normalization_1 = nn.BatchNorm2d(F1)\n",
    "\n",
    "        # Multi-scale convolution layers (three different kernel sizes)\n",
    "        self.conv2d_small = nn.Conv2d(F1, F1, kernel_size=(1, 3), padding=(0, 1))   # Small kernel\n",
    "        self.conv2d_medium = nn.Conv2d(F1, F1, kernel_size=(1, 5), padding=(0, 2))  # Medium kernel\n",
    "        self.conv2d_large = nn.Conv2d(F1, F1, kernel_size=(1, 7), padding=(0, 3))   # Large kernel\n",
    "        \n",
    "        # Batch normalization for multi-scale outputs\n",
    "        self.Batch_normalization_multiscale = nn.BatchNorm2d(F1 * 3)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Layer 2: Depthwise convolution\n",
    "        self.Depthwise_conv2D = nn.Conv2d(F1 * 3, F1 * 3, kernel_size_2, groups=F1 * 3)\n",
    "        self.Batch_normalization_2 = nn.BatchNorm2d(F1 * 3)\n",
    "        self.Elu = nn.ELU()\n",
    "        self.Average_pooling2D_1 = nn.AvgPool2d(kernel_avgpool_1)\n",
    "        self.Dropout = nn.Dropout2d(dropout_rate)\n",
    "\n",
    "        # Layer 3: Separable convolution\n",
    "        self.Separable_conv2D_depth = nn.Conv2d(F1 * 3, F1 * 3, kernel_size_3, padding=kernel_padding_3, groups=F1 * 3)\n",
    "        self.Separable_conv2D_point = nn.Conv2d(F1 * 3, F2, kernel_size_4)\n",
    "        self.Batch_normalization_3 = nn.BatchNorm2d(F2)\n",
    "        self.Average_pooling2D_2 = nn.AvgPool2d(kernel_avgpool_2)\n",
    "\n",
    "        # **Squeeze-and-Excitation Layer (added)**\n",
    "        self.se_block = SEBlock(F2)\n",
    "\n",
    "        # LSTM layer (added)\n",
    "        self.lstm_hidden_size = 128\n",
    "        # Modify to use Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(F2, self.lstm_hidden_size, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Layer 4: Flatten and fully connected layers\n",
    "        self.Flatten = nn.Flatten()\n",
    "        # Fixed: Since we're using bidirectional LSTM, output size becomes 2 * lstm_hidden_size\n",
    "        self.Dense = nn.Linear(self.lstm_hidden_size * 2, num_class)  # *2 for bidirectional LSTM\n",
    "        self.Softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1: Initial convolution + batch normalization\n",
    "        y = self.Batch_normalization_1(self.conv2d(x))\n",
    "\n",
    "        # Multi-scale convolution layer: Apply three different convolutions\n",
    "        y_small = self.conv2d_small(y)   # Small kernel\n",
    "        y_medium = self.conv2d_medium(y)  # Medium kernel\n",
    "        y_large = self.conv2d_large(y)   # Large kernel\n",
    "        \n",
    "        # Concatenate the three outputs along the channel dimension\n",
    "        y = torch.cat((y_small, y_medium, y_large), dim=1)\n",
    "        \n",
    "        # Apply batch normalization and ReLU\n",
    "        y = self.relu(self.Batch_normalization_multiscale(y))\n",
    "\n",
    "        # Layer 2: Depthwise convolution + batch normalization + activation\n",
    "        y = self.Batch_normalization_2(self.Depthwise_conv2D(y))\n",
    "        y = self.Elu(y)\n",
    "        y = self.Dropout(self.Average_pooling2D_1(y))\n",
    "\n",
    "        # Layer 3: Separable convolution + batch normalization + activation\n",
    "        y = self.Separable_conv2D_depth(y)\n",
    "        y = self.Batch_normalization_3(self.Separable_conv2D_point(y))\n",
    "        y = self.Elu(y)\n",
    "        y = self.Dropout(self.Average_pooling2D_2(y))\n",
    "\n",
    "        # **Squeeze-and-Excitation Module**\n",
    "        y = self.se_block(y)  # Apply SE block\n",
    "\n",
    "        # LSTM layer\n",
    "        y = y.permute(0, 2, 3, 1)  # Change the shape to (batch_size, time_steps, channels)\n",
    "        y = y.reshape(x.size(0), -1, F2)  # Reshape to match LSTM input format (batch_size, time_steps, features)\n",
    "\n",
    "        # Get the LSTM output\n",
    "        y, (h_n, c_n) = self.lstm(y)  # h_n: (num_layers * num_directions, batch_size, lstm_hidden_size)\n",
    "\n",
    "        # Extract the last hidden state from the bidirectional LSTM\n",
    "        y = torch.cat((h_n[0], h_n[1]), dim=-1)  # Concatenate the hidden states of both directions (h_n[0] and h_n[1])\n",
    "\n",
    "        # Layer 4: Flatten and fully connected layer\n",
    "        y = self.Dense(y)  # Linear layer to match output dimensions\n",
    "        y = self.Softmax(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "# 初始化模型和优化器\n",
    "model = EEGNetWithSE().to(device)  # 初始化模型并确保它在 GPU 上\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc43ff4-325c-417d-9c95-e4cf8b09a1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
